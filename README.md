# Using Unreal Engine with llama.cpp for AMD GPU.
### UEllamaCpp is an Unreal Engine project that uses llama.cpp for LLM inference. The main interface for llama.cpp is the thirdparty plugin llamaCppPlugin 

### Requires following libs:
- OpenMP(libomp.lib)
- AMD HIP(amdhip64.lib)
- AMD HIP(rocblas.lib)
- AMD HIP(hipblas.lib)
- llama.cpp(common.lib)
- llama.cpp(llama.lib)
- llama.cpp(ggml-base.lib)
- llama.cpp(ggml.lib)
- llama.cpp(ggml-hip.lib)
- llama.cpp(ggml-cpu.lib)
