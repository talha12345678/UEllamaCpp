# Using Unreal Engine with llama.cpp for AMD GPU.
## UEllamaCpp is a Unreal Engine project that uses llama.cpp for LLM inference 

### Requires following libs:
- OpenMP(libomp.lib)
- AMD HIP(amdhip64.lib)
- AMD HIP(rocblas.lib)
- AMD HIP(hipblas.lib)
- llama.cpp(common.lib)
- llama.cpp(llama.lib)
- llama.cpp(ggml-base.lib)
- llama.cpp(ggml.lib)
- llama.cpp(ggml-hip.lib)
- llama.cpp(ggml-cpu.lib)
